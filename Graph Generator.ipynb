{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8968d38-c396-498f-96ce-e9485d1a72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet neo4j langchain-community langchain-core langchain-openai langchain-text-splitters tiktoken wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486a4f9-a2a7-4064-b6a9-c4d8a3c04000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import getpass\n",
    "import os\n",
    "from datetime import datetime\n",
    "from hashlib import md5\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2edf07-a59b-4f03-ac2a-8ab224f90c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://21a8defc.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"7gnTfLGmyZ9ZapK2w6B6iUdA88NAOF3Q3pR6NwNuRBM\"\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:AtomicFact) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:KeyElement) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d755e-04bb-400a-81e3-384e918bc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64637751-566c-4206-8690-c49484a8207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaQueryRun(\n",
    "    api_wrapper=WikipediaAPIWrapper(doc_content_chars_max=10000)\n",
    ")\n",
    "text = wikipedia.run(\"Joan of Arc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30a9d7-8f43-4767-9516-84072287112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "construction_system = \"\"\"\n",
    "You are now an intelligent assistant tasked with meticulously extracting both key elements and\n",
    "atomic facts from a long text.\n",
    "1. Key Elements: The essential nouns (e.g., characters, times, events, places, numbers), verbs (e.g.,\n",
    "actions), and adjectives (e.g., states, feelings) that are pivotal to the textâ€™s narrative.\n",
    "2. Atomic Facts: The smallest, indivisible facts, presented as concise sentences. These include\n",
    "propositions, theories, existences, concepts, and implicit elements like logic, causality, event\n",
    "sequences, interpersonal relationships, timelines, etc.\n",
    "Requirements:\n",
    "#####\n",
    "1. Ensure that all identified key elements are reflected within the corresponding atomic facts.\n",
    "2. You should extract key elements and atomic facts comprehensively, especially those that are\n",
    "important and potentially query-worthy and do not leave out details.\n",
    "3. Whenever applicable, replace pronouns with their specific noun counterparts (e.g., change I, He,\n",
    "She to actual names).\n",
    "4. Ensure that the key elements and atomic facts you extract are presented in the same language as\n",
    "the original text (e.g., English or Chinese).\n",
    "\"\"\"\n",
    "\n",
    "construction_human = \"\"\"Use the given format to extract information from the \n",
    "following input: {input}\"\"\"\n",
    "\n",
    "construction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            construction_system,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Use the given format to extract information from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae006c-b1b5-4112-ae8a-21c43b28ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomicFact(BaseModel):\n",
    "    key_elements: List[str] = Field(description=\"\"\"The essential nouns (e.g., characters, times, events, places, numbers), verbs (e.g.,\n",
    "actions), and adjectives (e.g., states, feelings) that are pivotal to the atomic fact's narrative.\"\"\")\n",
    "    atomic_fact: str = Field(description=\"\"\"The smallest, indivisible facts, presented as concise sentences. These include\n",
    "propositions, theories, existences, concepts, and implicit elements like logic, causality, event\n",
    "sequences, interpersonal relationships, timelines, etc.\"\"\")\n",
    "\n",
    "class Extraction(BaseModel):\n",
    "    atomic_facts: List[AtomicFact] = Field(description=\"List of atomic facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5189df-a8e0-46fc-9148-78f7ada47a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0.1)\n",
    "structured_llm = model.with_structured_output(Extraction)\n",
    "\n",
    "construction_chain = construction_prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e355c2-5c16-4b3d-88ba-63838434730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_query = \"\"\"\n",
    "MERGE (d:Document {id:$document_name})\n",
    "WITH d\n",
    "UNWIND $data AS row\n",
    "MERGE (c:Chunk {id: row.chunk_id})\n",
    "SET c.text = row.chunk_text,\n",
    "    c.index = row.index,\n",
    "    c.document_name = row.document_name\n",
    "MERGE (d)-[:HAS_CHUNK]->(c)\n",
    "WITH c, row\n",
    "UNWIND row.atomic_facts AS af\n",
    "MERGE (a:AtomicFact {id: af.id})\n",
    "SET a.text = af.atomic_fact\n",
    "MERGE (c)-[:HAS_ATOMIC_FACT]->(a)\n",
    "WITH c, a, af\n",
    "UNWIND af.key_elements AS ke\n",
    "MERGE (k:KeyElement {id: ke})\n",
    "MERGE (a)-[:HAS_KEY_ELEMENT]->(k)\n",
    "\"\"\"\n",
    "\n",
    "def encode_md5(text):\n",
    "    return md5(text.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57ec29-ed49-4488-9512-4df7ad921355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper used 2k token size\n",
    "async def process_document(text, document_name, chunk_size=2000, chunk_overlap=200):\n",
    "    start = datetime.now()\n",
    "    print(f\"Started extraction at: {start}\")\n",
    "    text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_text(text)\n",
    "    print(f\"Total text chunks: {len(texts)}\")\n",
    "    tasks = [\n",
    "        asyncio.create_task(construction_chain.ainvoke({\"input\":chunk_text}))\n",
    "        for index, chunk_text in enumerate(texts)\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(f\"Finished LLM extraction after: {datetime.now() - start}\")\n",
    "    docs = [el.dict() for el in results]\n",
    "    for index, doc in enumerate(docs):\n",
    "        doc['chunk_id'] = encode_md5(texts[index])\n",
    "        doc['chunk_text'] = texts[index]\n",
    "        doc['index'] = index\n",
    "        for af in doc[\"atomic_facts\"]:\n",
    "            af[\"id\"] = encode_md5(af[\"atomic_fact\"])\n",
    "    # Import chunks/atomic facts/key elements\n",
    "    graph.query(import_query, \n",
    "            params={\"data\": docs, \"document_name\": document_name})\n",
    "    # Create next relationships between chunks\n",
    "    graph.query(\"\"\"MATCH (c:Chunk)<-[:HAS_CHUNK]-(d:Document)\n",
    "WHERE d.id = $document_name\n",
    "WITH c ORDER BY c.index WITH collect(c) AS nodes\n",
    "UNWIND range(0, size(nodes) -2) AS index\n",
    "WITH nodes[index] AS start, nodes[index + 1] AS end\n",
    "MERGE (start)-[:NEXT]->(end)\n",
    "\"\"\",\n",
    "           params={\"document_name\":document_name})\n",
    "    print(f\"Finished import at: {datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777e2cc-4a82-4b87-b42c-fcbabdb24380",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_document(text, \"Joan of Arc\", chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ec589-26a9-49f1-ae0e-84aef1a59fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "atomic_facts = graph.query(\"MATCH (a:AtomicFact) RETURN a.text AS text\")\n",
    "df = pd.DataFrame.from_records(\n",
    "    [{\"tokens\": num_tokens_from_string(el[\"text\"])} for el in atomic_facts]\n",
    ")\n",
    "\n",
    "sns.histplot(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe12ef-8bb2-4342-b312-cb9c4b9c04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\"\"\"MATCH (a:AtomicFact) \n",
    "RETURN a.text AS text\n",
    "ORDER BY size(text) ASC LIMIT 3\n",
    "UNION ALL\n",
    "MATCH (a:AtomicFact) \n",
    "RETURN a.text AS text\n",
    "ORDER BY size(text) DESC LIMIT 3\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bd631-d972-4256-884e-51a390cf1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph.query(\"\"\"\n",
    "MATCH (a:KeyElement) \n",
    "RETURN a.id AS key, \n",
    "       count{(a)<-[:HAS_KEY_ELEMENT]-()} AS connections\n",
    "ORDER BY connections DESC LIMIT 5\"\"\")\n",
    "df = pd.DataFrame.from_records(data)\n",
    "sns.barplot(df, x='key', y='connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e24433-5464-4ba9-83e4-faa29ba4267b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
